---
title: "p8105_hw2_jz3902"
author: "Jinghan Zhao"
date: "2024-09-27"
output: github_document
---

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

### Import and clean the data

The original dataset contains variables including: division, line, station name, station latitude / longitude, routes served, entrance type, entry, vending, staff and staff hours, ADA compliance and notes, free crossover, north south / east west street, corner, entrance latitude / longitude, station location and entrance location.

Data cleaning steps: clean variable names -> select variables in interest -> convert the `entry` variable from character to a logical variable by `case_match()`.

```{r data_cleaning_1, message = FALSE}
transit_df = 
  read_csv("HW2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )

```

The resulting dataset has `r nrow(transit_df)` rows and `r ncol(transit_df)` columns, which contains variables including: line, station name, station latitude / longitude, routes served, entrance type, entry, vending and ADA compliance.


### Distinct stations

Distinct stations are defined by line and station name.

```{r distinct_stations}
transit_df %>% 
  distinct(line, station_name)
```

There are 465 distinct stations.


### ADA compliant

```{r ada_compliant}
transit_df %>%
  filter(ada == TRUE) %>% 
  distinct(line, station_name)
```

There are 84 ADA compliant stations.


### Vending

Calculate the numerator (allow entrance + no vending) and denominator (no vending) respectively, then calculate the proportion.

```{r vending}
no_vending = 
  transit_df %>%
  filter(vending == "NO") %>% 
  nrow()

entry_no_vending = 
  transit_df %>%
  filter(vending == "NO", entry == TRUE) %>% 
  nrow()

propo_vending = entry_no_vending / no_vending
```

There are `r propo_vending * 100`% of stations without vending allow entrance.


### Display routes

The original variable type of `route1:route7` are character, yet `route8:route11` are numeric, so they cannot combine together. Therefore, I convert `route8:route11` to character first, then do `pivot_longer()`.

```{r routes}
transit_tidy_df =
  transit_df %>% 
  mutate(
    across(route8:route11, as.character)
  ) %>% 
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    values_drop_na = TRUE)
```

Answering questions:

```{r routes_question}
transit_tidy_df %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name)

transit_tidy_df %>% 
  filter(route_name == "A", ada == TRUE) %>% 
  distinct(line, station_name)
```

There are 60 distinct stations serve the A train.

There are 17 ADA compliant stations that serve the A train.


## Problem 2

### Import and clean the data

Steps: import dataset (claim the sheet and cell range) -> clean variable names -> do some mutating in need

```{r data_cleaning_2}
mr_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N586") %>% 
  janitor::clean_names() %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls),
    type = "mr_trash",
    year = as.numeric(year)
  )

professor_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M108") %>% 
  janitor::clean_names() %>% 
  mutate(
    type = "professor_trash"
  )

gwynnda_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:L157") %>% 
  janitor::clean_names() %>% 
  mutate(
    type = "gwynnda_trash"
  )

```

### Combine datasets

```{r trash_combining}
trash_df = 
  bind_rows(mr_trash_df, professor_trash_df, gwynnda_trash_df) %>% 
  relocate(type)
```

There are `r nrow(trash_df)` observations and `r ncol(trash_df)` columns in the resulting dataset. Here are the first few lines of the dataset to show key variables:

```{r trash_key_var}
trash_df %>% 
  head() %>% 
  knitr::kable()
```

Answering questions:

```{r trash_question}
prof_weight = 
  trash_df %>% 
  filter(type == "professor_trash") %>% 
  pull(weight_tons) %>% 
  sum()

gwyn_cigarette = 
  trash_df %>% 
  filter(type == "gwynnda_trash",
         year == 2022,
         month == "June") %>% 
  pull(cigarette_butts) %>% 
  sum()
```

The total weight of trash collected by Professor Trash Wheel is `r prof_weight` tons.

The total number of cigarette butts collected by Gwynnda in June of 2022 is `r format(gwyn_cigarette, scientific=FALSE)`.


## Problem 3

### Import and clean the data

```{r data_cleaning_3, message = FALSE}
bakers_df = 
  read_csv("HW2_data/gbb_datasets/bakers.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    baker_first_name = sub(" .*", "", baker_name)
    )

bakes_df = 
  read_csv("HW2_data/gbb_datasets/bakes.csv", 
           na = c("NA", "N/A", "UNKNOWN", "Unknown", "")) %>% 
  janitor::clean_names() %>% 
  mutate(
    baker = ifelse(baker == "\"Jo\"", "Jo", baker)
    ) %>% 
  rename(baker_first_name = baker) %>% 
  arrange(baker_first_name)


results_df = 
  read_csv("HW2_data/gbb_datasets/results.csv",
           skip = 2) %>% 
  janitor::clean_names() %>% 
  rename(baker_first_name = baker) %>% 
  arrange(baker_first_name) %>% 
  drop_na(result)
```

Data cleaning steps: import dataset -> clean variable names -> wrangle each of datasets

`bakers_df`: 

* Pick up the baker's first name to match the other datasets

`bakes_df`:

* Unknown values are uniformly recorded as NA

* For the baker named `"Jo"`, convert the name into `Jo` to match the other datasets

* Rename variable `baker` to `baker_first_name`, to match the first dataset `bakers_df`

* Sort baker's name alphabetically

`results_df`:

* Skip some lines which not contain observations

* Rename variable `baker` to `baker_first_name`, to match the first dataset `bakers_df`

* Sort baker's name alphabetically

* By looking at the dataset, we can see that the eliminated bakers have NA in `result` after they are OUT, which means they will no longer participate in the competition. Therefore, NA in `result` should be dropped.

### Organize bakers datasets

```{r baker_organizing}
baker_bake_df = 
  left_join(
    bakers_df, 
    bakes_df, 
    join_by(baker_first_name, series)
  )

baker_organized_df = 
  full_join(
    baker_bake_df,
    results_df,
    join_by(baker_first_name, series, episode)
  ) %>% 
  group_by(baker_first_name, series) %>% 
  fill(baker_name:hometown) %>% 
  ungroup() %>% 
  arrange(baker_first_name) %>% 
  drop_na(episode)
```

1. Join `bakers.csv` and `bakes.csv` first, by baker's first name + series. The result is **the bakers+bakes dataset**.

2. Join **the bakers+bakes dataset** with `results.csv`, by baker's first name + series + episode.

3. By looking at the dataset, we can see some bakers only have episode information in `results.csv`, so the rows cannot match with those in **the bakers+bakes dataset** (where episode information is NA). To fix this, I fill those NAs with `group_by()` and `fill()`, then remove the grouping after the operation. 

4. Next, sort baker's first name alphabetically, and drop the rows that have NA in `episode`. (Explanation: These rows are used as reference to fill in *step 3*, and only have the information from **the bakers+bakes dataset** but not from `results.csv`. Therefore, these rows can be dropped after **the bakers+bakes dataset** information is filled.)


### Check across datasets

```{r baker_checking}
anti_join(
  bakers_df,
  baker_organized_df,
    join_by(baker_first_name, series)
  )

anti_join(
  bakes_df,
  baker_organized_df,
    join_by(baker_first_name, series, episode)
  )

anti_join(
  results_df,
  baker_organized_df,
    join_by(baker_first_name, series, episode)
  )
```

Check for completeness and correctness across datasets. View the three datasets respectively.

### Resulting dataset

```{r baker_resulting}
baker_result_df = 
baker_organized_df %>% 
  select(baker_first_name, baker_name, baker_age, baker_occupation, hometown, series, episode, technical, result, signature_bake, show_stopper) %>% 
  rename(baker_full_name = baker_name)

baker_result_df %>% 
write_csv("HW2_data/gbb_datasets/baker_result_df.csv")
```

1. Organize the dataset in a meaningful order and name variables properly.

* Variables: baker's first name and full name -> baker's basic information (age, occupation, hometown) -> series and episode involved ->  competition technical and result -> signature bake and show stopper

* Observations: Alphabetical order of baker's first name

2. Export the result as a CSV

3. Brief discussion

```{r}
baker_result_df
```

* There are `r nrow(baker_result_df)` rows and `r ncol(baker_result_df)` columns in the final dataset. The dataset shows information of the bakers, their bakes and their performance.


### Winners

```{r baker_winner}
baker_result_df %>% 
  select(series, result, baker_first_name) %>% 
  filter(series >= 5, series <= 10,
         result %in% c("WINNER", "STAR BAKER")) %>%
  mutate(
    result = case_match(
      result,
      "WINNER" ~ "Winner",
      "STAR BAKER" ~ "Star Baker"
    )
  ) %>% 
  arrange(series, result) %>% 
  distinct() %>% 
  pivot_wider(
    names_from = result,
    values_from = baker_first_name,
    values_fn = list
  ) %>% 
  rename(Series = series) %>% 
  knitr::kable()
```

**The star baker and winner of each episode in Seasons 5 through 10**

Steps:

1. Select columns and filter rows in interest

2. Sort by series and baker's first name

3. Obtain all the unique lines

4. Organize variable names

5. Generate a reader-friendly table

### Comments on winners

```{r baker_winner_predict}
baker_result_df %>% 
  select(series, result, baker_first_name) %>% 
  filter(series >= 5, series <= 10,
         result %in% c("WINNER", "STAR BAKER")) %>%
  arrange(baker_first_name) %>% 
  distinct() %>% 
  knitr::kable()
```

To get a deeper understanding of the table, I arranged the table by bakerâ€™s name to see how each person performed.

* Most of them got STAR BAKER once, and a few of STAR BAKER also got WINNER.

* What surprise me is that David, the WINNER of season 10, only got WINNER but not STAR BAKER. Furthermore, Kate got STAR BAKER twice but didn't get WINNER in both seasons. 

* Based on these situations, I think there are many factors that determine the overall winner, and we can't simply judge from the results.


### Viewers





