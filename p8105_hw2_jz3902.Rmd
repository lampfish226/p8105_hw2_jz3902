---
title: "p8105_hw2_jz3902"
author: "Jinghan Zhao"
date: "2024-09-27"
output: github_document
---

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

### Import and clean the data

The original dataset contains variables including: division, line, station name, station latitude / longitude, routes served, entrance type, entry, vending, staff and staff hours, ADA compliance and notes, free crossover, north south / east west street, corner, entrance latitude / longitude, station location and entrance location.

Data cleaning steps: clean variable names -> select variables in interest -> convert the `entry` variable from character to a logical variable by `case_match()`.

```{r data_cleaning_1, message = FALSE}
transit_df = 
  read_csv("HW2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )

```

The resulting dataset has `r nrow(transit_df)` rows and `r ncol(transit_df)` columns, which contains variables including: line, station name, station latitude / longitude, routes served, entrance type, entry, vending and ADA compliance.


### Distinct stations

Distinct stations are defined by line and station name.

```{r distinct_stations}
transit_df %>% 
  distinct(line, station_name)
```

There are 465 distinct stations.


### ADA compliant

```{r ada_compliant}
transit_df %>%
  filter(ada == TRUE) %>% 
  distinct(line, station_name)
```

There are 84 ADA compliant stations.


### Vending

Calculate the numerator (allow entrance + no vending) and denominator (no vending) respectively, then calculate the proportion.

```{r vending}
no_vending = 
  transit_df %>%
  filter(vending == "NO") %>% 
  nrow()

entry_no_vending = 
  transit_df %>%
  filter(vending == "NO", entry == TRUE) %>% 
  nrow()

propo_vending = entry_no_vending / no_vending
```

There are `r propo_vending * 100`% of stations without vending allow entrance.


### Display routes

The original variable type of `route1:route7` are character, yet `route8:route11` are numeric, so they cannot combine together. Therefore, I convert `route8:route11` to character first, then do `pivot_longer()`.

```{r routes}
transit_tidy_df =
  transit_df %>% 
  mutate(
    across(route8:route11, as.character)
  ) %>% 
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    values_drop_na = TRUE)
```

Answering questions:

```{r routes_question}
transit_tidy_df %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name)

transit_tidy_df %>% 
  filter(route_name == "A", ada == TRUE) %>% 
  distinct(line, station_name)
```

There are 60 distinct stations serve the A train.

There are 17 ADA compliant stations that serve the A train.


## Problem 2

### Import and clean the data

Steps: import dataset (claim the sheet and cell range) -> clean variable names -> do some mutating in need

```{r data_cleaning_2}
mr_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N586") %>% 
  janitor::clean_names() %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls),
    type = "mr_trash",
    year = as.numeric(year)
  )

professor_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M108") %>% 
  janitor::clean_names() %>% 
  mutate(
    type = "professor_trash"
  )

gwynnda_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:L157") %>% 
  janitor::clean_names() %>% 
  mutate(
    type = "gwynnda_trash"
  )

```

### Combine datasets

```{r trash_combining}
trash_df = 
  bind_rows(mr_trash_df, professor_trash_df, gwynnda_trash_df) %>% 
  relocate(type)
```

There are `r nrow(trash_df)` observations and `r ncol(trash_df)` columns in the resulting dataset. Here are the first few lines of the dataset to show key variables:

```{r trash_key_var}
trash_df %>% 
  head() %>% 
  knitr::kable()
```

Answering questions:

```{r trash_question}
prof_weight = 
  trash_df %>% 
  filter(type == "professor_trash") %>% 
  pull(weight_tons) %>% 
  sum()

gwyn_cigarette = 
  trash_df %>% 
  filter(type == "gwynnda_trash",
         year == 2022,
         month == "June") %>% 
  pull(cigarette_butts) %>% 
  sum()
```

The total weight of trash collected by Professor Trash Wheel is `r prof_weight` tons.

The total number of cigarette butts collected by Gwynnda in June of 2022 is `r format(gwyn_cigarette, scientific=FALSE)`.


## Problem 3

### Import and clean the data

```{r data_cleaning_3, message = FALSE}
bakers_df = 
  read_csv("HW2_data/gbb_datasets/bakers.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    baker_first_name = sub(" .*", "", baker_name)
    )

bakes_df = 
  read_csv("HW2_data/gbb_datasets/bakes.csv", 
           na = c("NA", "N/A", "UNKNOWN", "Unknown", "")) %>% 
  janitor::clean_names() %>% 
  mutate(
    baker = ifelse(baker == "\"Jo\"", "Jo", baker)
    ) %>% 
  rename(baker_first_name = baker) %>% 
  arrange(baker_first_name)


results_df = 
  read_csv("HW2_data/gbb_datasets/results.csv",
           skip = 2) %>% 
  janitor::clean_names() %>% 
  rename(baker_first_name = baker) %>% 
  arrange(baker_first_name) %>% 
  drop_na(result)
```

Data cleaning steps: import dataset -> clean variable names -> wrangle each of datasets

`bakers_df`: 

* Pick up the baker's first name to match the other datasets

`bakes_df`:

* Unknown values are uniformly recorded as NA

* For the baker named `"Jo"`, convert the name into `Jo` to match the other datasets

* Rename variable `baker` to `baker_first_name`, to match the first dataset `bakers_df`

* Sort baker's name alphabetically

`results_df`:

* Skip some lines which not contain observations

* Rename variable `baker` to `baker_first_name`, to match the first dataset `bakers_df`

* Sort baker's name alphabetically

* By looking at the dataset, we can see that the eliminated bakers have NA in `result` after they are OUT, which means they will no longer participate in the competition. Therefore, NA in `result` should be dropped.

### Organize bakers datasets

```{r baker_organizing}
baker_bake_df = 
  left_join(
    bakers_df, 
    bakes_df, 
    join_by(baker_first_name, series)
  )

baker_organized_df = 
  full_join(
    baker_bake_df,
    results_df,
    join_by(baker_first_name, series, episode)
  ) %>% 
  group_by(baker_first_name, series) %>% 
  fill(baker_name:hometown) %>% 
  ungroup() %>% 
  arrange(baker_name)
```




### Check across datasets

```{r baker_checking}
anti_join(
  results_df,
  baker_organized_df,
    join_by(baker_first_name, series)
  )

anti_join(
  bakers_df,
  baker_organized_df,
    join_by(baker_first_name, series)
  )

anti_join(
  bakes_df,
  baker_organized_df,
    join_by(baker_first_name, series)
  )
```


### Winners





### Viewers





