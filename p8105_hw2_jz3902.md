p8105_hw2_jz3902
================
Jinghan Zhao
2024-09-27

## Problem 1

### Import and clean the data

The original dataset contains variables including: division, line,
station name, station latitude / longitude, routes served, entrance
type, entry, vending, staff and staff hours, ADA compliance and notes,
free crossover, north south / east west street, corner, entrance
latitude / longitude, station location and entrance location.

Data cleaning steps: clean variable names -\> select variables in
interest -\> convert the `entry` variable from character to a logical
variable by `case_match()`.

``` r
transit_df = 
  read_csv("HW2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )
```

The resulting dataset has 1868 rows and 19 columns, which contains
variables including: line, station name, station latitude / longitude,
routes served, entrance type, entry, vending and ADA compliance.

### Distinct stations

Distinct stations are defined by line and station name.

``` r
transit_df %>% 
  distinct(line, station_name)
```

    ## # A tibble: 465 × 2
    ##    line     station_name            
    ##    <chr>    <chr>                   
    ##  1 4 Avenue 25th St                 
    ##  2 4 Avenue 36th St                 
    ##  3 4 Avenue 45th St                 
    ##  4 4 Avenue 53rd St                 
    ##  5 4 Avenue 59th St                 
    ##  6 4 Avenue 77th St                 
    ##  7 4 Avenue 86th St                 
    ##  8 4 Avenue 95th St                 
    ##  9 4 Avenue 9th St                  
    ## 10 4 Avenue Atlantic Av-Barclays Ctr
    ## # ℹ 455 more rows

There are 465 distinct stations.

### ADA compliant

``` r
transit_df %>%
  filter(ada == TRUE) %>% 
  distinct(line, station_name)
```

    ## # A tibble: 84 × 2
    ##    line            station_name                  
    ##    <chr>           <chr>                         
    ##  1 4 Avenue        Atlantic Av-Barclays Ctr      
    ##  2 4 Avenue        DeKalb Av                     
    ##  3 4 Avenue        Pacific St                    
    ##  4 42nd St Shuttle Grand Central                 
    ##  5 6 Avenue        34th St                       
    ##  6 6 Avenue        47-50th Sts Rockefeller Center
    ##  7 6 Avenue        Church Av                     
    ##  8 63rd Street     21st St                       
    ##  9 63rd Street     Lexington Av                  
    ## 10 63rd Street     Roosevelt Island              
    ## # ℹ 74 more rows

There are 84 ADA compliant stations.

### Vending

Calculate the numerator (allow entrance + no vending) and denominator
(no vending) respectively, then calculate the proportion.

``` r
no_vending = 
  transit_df %>%
  filter(vending == "NO") %>% 
  nrow()

entry_no_vending = 
  transit_df %>%
  filter(vending == "NO", entry == TRUE) %>% 
  nrow()

propo_vending = entry_no_vending / no_vending
```

There are 37.704918% of stations without vending allow entrance.

### Display routes

The original variable type of `route1:route7` are character, yet
`route8:route11` are numeric, so they cannot combine together.
Therefore, I convert `route8:route11` to character first, then do
`pivot_longer()`.

``` r
transit_tidy_df =
  transit_df %>% 
  mutate(
    across(route8:route11, as.character)
  ) %>% 
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    values_drop_na = TRUE)
```

Answering questions:

``` r
transit_tidy_df %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name)
```

    ## # A tibble: 60 × 2
    ##    line            station_name                 
    ##    <chr>           <chr>                        
    ##  1 42nd St Shuttle Times Square                 
    ##  2 8 Avenue        125th St                     
    ##  3 8 Avenue        145th St                     
    ##  4 8 Avenue        14th St                      
    ##  5 8 Avenue        168th St - Washington Heights
    ##  6 8 Avenue        175th St                     
    ##  7 8 Avenue        181st St                     
    ##  8 8 Avenue        190th St                     
    ##  9 8 Avenue        34th St                      
    ## 10 8 Avenue        42nd St                      
    ## # ℹ 50 more rows

``` r
transit_tidy_df %>% 
  filter(route_name == "A", ada == TRUE) %>% 
  distinct(line, station_name)
```

    ## # A tibble: 17 × 2
    ##    line             station_name                 
    ##    <chr>            <chr>                        
    ##  1 8 Avenue         14th St                      
    ##  2 8 Avenue         168th St - Washington Heights
    ##  3 8 Avenue         175th St                     
    ##  4 8 Avenue         34th St                      
    ##  5 8 Avenue         42nd St                      
    ##  6 8 Avenue         59th St                      
    ##  7 8 Avenue         Inwood - 207th St            
    ##  8 8 Avenue         West 4th St                  
    ##  9 8 Avenue         World Trade Center           
    ## 10 Broadway         Times Square-42nd St         
    ## 11 Broadway-7th Ave 59th St-Columbus Circle      
    ## 12 Broadway-7th Ave Times Square                 
    ## 13 Canarsie         8th Av                       
    ## 14 Franklin         Franklin Av                  
    ## 15 Fulton           Euclid Av                    
    ## 16 Fulton           Franklin Av                  
    ## 17 Rockaway         Howard Beach

There are 60 distinct stations serve the A train.

There are 17 ADA compliant stations that serve the A train.

## Problem 2

### Import and clean the data

Steps: import dataset (claim the sheet and cell range) -\> clean
variable names -\> do some mutating in need

``` r
mr_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N586") %>% 
  janitor::clean_names() %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls),
    type = "mr_trash",
    year = as.numeric(year)
  )

professor_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M108") %>% 
  janitor::clean_names() %>% 
  mutate(
    type = "professor_trash"
  )

gwynnda_trash_df = 
  read_excel("HW2_data/202309 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:L157") %>% 
  janitor::clean_names() %>% 
  mutate(
    type = "gwynnda_trash"
  )
```

### Combine datasets

``` r
trash_df = 
  bind_rows(mr_trash_df, professor_trash_df, gwynnda_trash_df) %>% 
  relocate(type)
```

There are 845 observations and 15 columns in the resulting dataset. Here
are the first few lines of the dataset to show key variables:

``` r
trash_df %>% 
  head() %>% 
  knitr::kable()
```

| type     | dumpster | month | year | date       | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | plastic_bags | wrappers | sports_balls | homes_powered |
|:---------|---------:|:------|-----:|:-----------|------------:|-------------------:|----------------:|------------:|----------------:|--------------:|-------------:|---------:|-------------:|--------------:|
| mr_trash |        1 | May   | 2014 | 2014-05-16 |        4.31 |                 18 |            1450 |        1820 |          126000 |            72 |          584 |     1162 |            7 |             0 |
| mr_trash |        2 | May   | 2014 | 2014-05-16 |        2.74 |                 13 |            1120 |        1030 |           91000 |            42 |          496 |      874 |            5 |             0 |
| mr_trash |        3 | May   | 2014 | 2014-05-16 |        3.45 |                 15 |            2450 |        3100 |          105000 |            50 |         1080 |     2032 |            6 |             0 |
| mr_trash |        4 | May   | 2014 | 2014-05-17 |        3.10 |                 15 |            2380 |        2730 |          100000 |            52 |          896 |     1971 |            6 |             0 |
| mr_trash |        5 | May   | 2014 | 2014-05-17 |        4.06 |                 18 |             980 |         870 |          120000 |            72 |          368 |      753 |            7 |             0 |
| mr_trash |        6 | May   | 2014 | 2014-05-20 |        2.71 |                 13 |            1430 |        2140 |           90000 |            46 |          672 |     1144 |            5 |             0 |

Answering questions:

``` r
prof_weight = 
  trash_df %>% 
  filter(type == "professor_trash") %>% 
  pull(weight_tons) %>% 
  sum()

gwyn_cigarette = 
  trash_df %>% 
  filter(type == "gwynnda_trash",
         year == 2022,
         month == "June") %>% 
  pull(cigarette_butts) %>% 
  sum()
```

The total weight of trash collected by Professor Trash Wheel is 216.26
tons.

The total number of cigarette butts collected by Gwynnda in June of 2022
is 18120.

## Problem 3

### Import and clean the data

``` r
bakers_df = 
  read_csv("HW2_data/gbb_datasets/bakers.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    baker_first_name = sub(" .*", "", baker_name)
    )

bakes_df = 
  read_csv("HW2_data/gbb_datasets/bakes.csv", 
           na = c("NA", "N/A", "UNKNOWN", "Unknown", "")) %>% 
  janitor::clean_names() %>% 
  mutate(
    baker = ifelse(baker == "\"Jo\"", "Jo", baker)
    ) %>% 
  rename(baker_first_name = baker) %>% 
  arrange(baker_first_name)


results_df = 
  read_csv("HW2_data/gbb_datasets/results.csv",
           skip = 2) %>% 
  janitor::clean_names() %>% 
  rename(baker_first_name = baker) %>% 
  arrange(baker_first_name) %>% 
  drop_na(result)
```

Data cleaning steps: import dataset -\> clean variable names -\> wrangle
each of datasets

`bakers_df`:

- Pick up the baker’s first name to match the other datasets

`bakes_df`:

- Unknown values are uniformly recorded as NA

- For the baker named `"Jo"`, convert the name into `Jo` to match the
  other datasets

- Rename variable `baker` to `baker_first_name`, to match the first
  dataset `bakers_df`

- Sort baker’s name alphabetically

`results_df`:

- Skip some lines which not contain observations

- Rename variable `baker` to `baker_first_name`, to match the first
  dataset `bakers_df`

- Sort baker’s name alphabetically

- By looking at the dataset, we can see that the eliminated bakers have
  NA in `result` after they are OUT, which means they will no longer
  participate in the competition. Therefore, NA in `result` should be
  dropped.

### Organize bakers datasets

``` r
baker_bake_df = 
  left_join(
    bakers_df, 
    bakes_df, 
    join_by(baker_first_name, series)
  )

baker_organized_df = 
  full_join(
    baker_bake_df,
    results_df,
    join_by(baker_first_name, series, episode)
  ) %>% 
  group_by(baker_first_name, series) %>% 
  fill(baker_name:hometown) %>% 
  ungroup() %>% 
  arrange(baker_name)
```

### Check across datasets

``` r
anti_join(
  results_df,
  baker_organized_df,
    join_by(baker_first_name, series)
  )
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker_first_name <chr>,
    ## #   technical <dbl>, result <chr>

``` r
anti_join(
  bakers_df,
  baker_organized_df,
    join_by(baker_first_name, series)
  )
```

    ## # A tibble: 0 × 6
    ## # ℹ 6 variables: baker_name <chr>, series <dbl>, baker_age <dbl>,
    ## #   baker_occupation <chr>, hometown <chr>, baker_first_name <chr>

``` r
anti_join(
  bakes_df,
  baker_organized_df,
    join_by(baker_first_name, series)
  )
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker_first_name <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

### Winners

### Viewers
